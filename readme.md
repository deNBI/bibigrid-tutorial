# Cloud User Meeting: BiBiGrid HandsOn

This tutorial is a reworked/optimized version of the HandsOn session of the **GCB 2019 in Heidelberg**.

## Prerequisits

- Python 3 (required)
- Openstack API access (required)
- [OpenstackClient](https://pypi.org/project/python-openstackclient/) (recommended)
- Linux (recommended)

## Download BiBiGrid

[[[Enter Link for BiBiGrid here]]]

## What will happen...

The goal of this session is to setup a small HPC cluster consisting of 3 nodes  (1 master, 2 workers) using BiBiGrid with [Slurm](https://slurm.schedmd.com/quickstart.html) (worload manager),  [Network File System](https://linux.die.net/man/5/nfs) (allows file sharing between servers) and [Theia](https://theia-ide.org/docs/user_getting_started/)  (Web IDE). This tutorial targets users running BiBiGrid on de.NBI cloud.

1. [Preperation](#preperation)
2. [Configuration](#configuration)


See our [de.NBI Wiki HandsOn](https://cloud.denbi.de/wiki/Tutorials/BiBiGrid/) for a more general tutorial. [[[[Remove if not needed]]]]

## Preperation

### Premade Template

Use the prefilled [configuration template](resources/bibigrid.yml) as a basis for your personal BiBiGrid configuration. Later in this tutorial you will use [OpenStackClient](https://pypi.org/project/python-openstackclient/) or access openstack dashboard manually to get all necessary configuration information from your project.

Copy the configuration template to `~/.config/bibigrid/`.

### Authentication

In this section you will create an [application credential](https://access.redhat.com/documentation/zh-cn/red_hat_openstack_platform/14/html/users_and_identity_management_guide/application_credentials) and download the autogenerated `clouds.yaml`. `clouds.yaml` contains all required authentication information. Follow the images:

![Navigation](images/ac_screen1.png)

Don't use the input field secret. As you can see its input is not hidden. OpenStack will generate a strong secret for you, if you leave it blank. Pick a sensible expiration date.

![Creation](images/ac_screen2.png)

Safe the downloaded `clouds.yaml` under `~/.config/openstack/` **and** `~/.config/bibigrid/`. That will allow both OpenstackClient and BiBiGrid to access it.

![Download](images/ac_screen3.png)

If you have OpenstackClient installed and `openstack subnet list --os-cloud=openstack` runs without error, you are ready to proceed.

## Configuration

### Access information

BiBiGrid needs to know where to look for the cloud and later as which user to access the servers. Therefore you need to set three keys: [region](https://docs.openstack.org/python-openstackclient/rocky/cli/command-objects/region.html), [availabilityZone](https://docs.openstack.org/nova/latest/admin/availability-zones.html) and [sshUser](https://www.redhat.com/sysadmin/access-remote-systems-ssh). Following the next steps you will be able to update the [premade template](#premade-template).

#### region

Determine the [region](https://docs.openstack.org/python-openstackclient/rocky/cli/command-objects/region.html) by running:

```
openstack region list --os-cloud=openstack
```

Set the template's `region` key to the result's `Region` entry.

#### availabilityZone

Determine your [availabilityZone](https://docs.openstack.org/nova/latest/admin/availability-zones.html) by running:

```
openstack availability zone list --os-cloud=openstack
```

If multiple zones are shown, pick default. Set the template's `availabilityZone` key to the result's `Zone Name` entry.

#### sshUser

The [sshUser](https://www.redhat.com/sysadmin/access-remote-systems-ssh) depends on your server image. Since we run on top of Ubuntu 22.04 the ssh-user is *ubuntu*. Set the template's `sshUser` key to `ubuntu`. We already did this for you.

### Network

We prepared a subnet for you. Determine your subnet's name or id by running:

```
openstack subnet list --os-cloud=openstack
```

### Instances

BiBiGrid needs to know `type` and `image` for each server. Since those are often identical for the workers, you can simply use the `count` key to indicate multiple workers with the same `type` and `image`.

#### Image
Images are virtual disks with a bootable operating system. Choosing an image means choosing the operating system of your server.

Since [images](https://docs.openstack.org/image-guide/introduction.html) are often updated, you need to look up the current active image using:

```
openstack image list --os-cloud=openstack | grep active
```

Since we will use Ubuntu 22.04 you might as well use:

```
openstack image list --os-cloud=openstack | grep active | grep "Ubuntu 22.04"
```

Set the template's `image` key of all instances to the result's `ID` entry (the first column) of the Ubuntu 22.04 row. All servers will share the same image.

#### Flavor

Flavors are available hardware configurations.

The following gives you a list of all flavors:

```
openstack flavor list --os-cloud=openstack
```

Set the template's `flavor` keys to flavors of your choice. You can use a different flavor for each instance.

#### master

```
masterInstance:
  type: de.NBI default
  image: [ubuntu-22.04-image-id]
```

#### worker
```
workerInstances:
  - type: de.NBI tiny
    image: [ubuntu-22.04-image-id]
    count: 2
```

The key `workerInstances` expects a list. Each list element is a `worker group` with a `image` + `type` combination and a `count`.
```
workerInstances:
  - type: de.NBI tiny
    image: [ubuntu-22.04-image-id]
    count: 1
  - type: de.NBI default
    image: [ubuntu-22.04-image-id]
    count: 1
```

### Waiting for post-launch Service

Some clouds run a post-launch service on every started instance. That might interrupt ansible. Thefore BiBiGrid needs to wait for your post-launch service to finish. For that BiBiGrid needs the service's name. Set the key `waitForService` to the service you would like to wait for. For Bielefeld this would be `de.NBI_Bielefeld_environment.service`. You should be able to find post-launch service names by taking a look at your location's [Computer Center Specific](https://cloud.denbi.de/wiki/) site - if a post-launch service exists for your location.

### Check Your Configuration
Run `./bibigrid.sh -i [path-to-bibigrid.yml] -ch -v` to check your configuration. `path-to-bibigrid.yml` is `bibigrid.yml` if you copied the configuration template to `~/.config/bibigrid/`. The commandline argument `-v` allows for greater verbosity which will make it easier for you to fix issues.

## The Cluster
`./bibigrid.sh -i bibigrid.yml -c` creates the cluster (executes only without error if check was successful). This will take up to 15 minutes.

```
[[CONTAINS EXAMPLE PRINT AFTER SUCCESSFULL CLUSTER CREATION]]
```

### List Running Cluster
Since it is possible to start more than one cluster at once, it can be helpful to list all running clusters:

Execute `./bibigrid.sh -i bibigrid.yml -l`. You will receive a general overview over all clusters started in your project.

### Cluster Login

#### Login Using the Theia Web IDE
Execute `./bibigrid.sh -i bibigrid.yml -ide -cid [cluster-id]` to connect to theia. You may even use `./bibigrid.sh -i bibigrid.yml -ide` since BiBiGrid will attempt to connect to the last created cluster if no cluster-id is given.

[Theia Web IDE](https://www.theia-ide.org/) allows you to work on your cloud instances more easily. Let's see how Theia works together with BiBiGrid. 

![Theia](images/theia.png)

If the theia option is enabled in the configuration, theia will be run as systemd service on localhost. You can connect to 

`java -jar bibigrid-openstack-2.0.8.jar --ide <clusterid>`

#### Hello World, Hello BiBiGrid!